\documentclass[a4paper,11pt]{article}

\usepackage{mlsubmit}

\begin{document}

\initmlsubmision{2} % assignment number
{Divyaksh Shukla}   % your name
{231110603}	% your roll number

\date{November 8, 2023}

\begin{mlsolution}

\begin{itemize}
    \item This is solved by taking the cluster which has its mean closest to the test point $x_n$ $$ \arg\min_{k}||x_n-\mu_k||^{2} $$
    \item If we assume the test point to be closest to a cluster mean, denoted by $\mu_{k}$ then we can get the update equation for $\mu_{k}$ by taking derivative of $\mathcal{L}$ w.r.t. $\mu_{k}$ $$ \frac{\partial \mathcal{L}}{\partial \mu_{k}} = -2||x_{n} - \mu_{k}|| $$ Which can be put into the update equation as \begin{equation}
        \mu_{k} = \mu_{k} + \eta ||x_{n} - \mu_{k}||
        \label{eq:k-means-sgd-update}
    \end{equation}
    \item In \ref{eq:k-means-sgd-update} we have taken all constants to be part of the step-size $\eta$. A good choice of $\eta$ would be a small value that decreases monotonically as the steps progress. By taking a small step size the cluster means will slowly progress towards the expected means and remain unaffected by noisy input datapoints.
\end{itemize}

% A vector symbol $\vb$, a symbol in blackboard font $\bR$, a symbol in calligraphic font $\cA$, \red{some} \green{colored} \blue{text}


\end{mlsolution}

\begin{mlsolution} 

My solution to problem 2


\end{mlsolution}

\begin{mlsolution}

Let us take $\vS^{\prime}=\frac{1}{N}\vX\vX^T$. \ref{eq:S-prime-eigenequation} represents the equation to calculate eigenvalue $\lambda^{\prime}$ and eigenvector $\vv$ of $\vS^{\prime}$
\begin{equation}
    \vS^{\prime} \vv = \lambda^{\prime} \vv
    \label{eq:S-prime-eigenequation}
\end{equation}

Now if we take the value of $\vS^{\prime}$ and pre-multiply with $\vX^T$ and readjust the values we get:

\begin{align}
    \frac{1}{N}\vX\vX^T\vv &= \lambda^{\prime} \vv \\
    \red{\frac{1}{N}\vX^T\vX}\blue{\vX^T\vv} &= \lambda^{\prime} \blue{\vX^T \vv} \\
    \red{\vS} \blue{\vu} &= \lambda^{\prime} \blue{\vu}
\end{align}

Thus the eigenvalue remains the same in both forms, only the eigenvectors change, which can be see in blue from Equation 4 and 5. By computing eigenvectors this way we can reduce the complexity of calculating eigenvalues for a $D\times D$ matrix to $N\times N$ matrix, which is feasible in this case as $D<N$.

\end{mlsolution}

\begin{mlsolution}

My solution to problem 4

\end{mlsolution}
	
\begin{mlsolution}

My solution to problem 5

\end{mlsolution}

\begin{mlsolution}

Solve this and if you can then give me 100

\end{mlsolution}


\end{document}
